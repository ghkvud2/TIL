### 1. 가상메모리

- 가상 메모리라는 것은 프로세스 전체가 메모리 내에 올라오지 않더라도 실행이 가능하도록 하는 기법이다.
- 이 기법의 장점은 사용자 프로세스가 메모리 용량보다 크더라도 실행이 가능하도록 한다는 것이다.
- 물론, `동적 로딩` 방법을 사용하면 프로세스 전체를 메모리에 올리지 않아도 되기는 하지만 이 방법은 프로그래머에게 특별한 주의와 추가적인 작업을 요구한다.

------

### 2. 배경

- 프로그램에는 잘 발생하지 않는 오류를 처리하는 코드가 존재한다. 이러한 오류들은 실질적으로 발생하는 빈도수가 적기 때문에, 이 코드들은 거의 실행되지 않는다.
- 또한, 전체 프로그램이 메모리에 올라가 있는 상태라고 하더라도, 프로세스의 모든 부분이 동시에 요구되지 않을 수 있다.
- 이러한 관점에서 봤을 때, 프로그램의 일부분만 메모리에 올려놓고 실행할 수 있다면 효율성을 높일 수 있다.

------

### 3. 요구 페이징 (Demand Paging)

- 프로그램 실행을 시작 할 때, 프로그램의 전부를 물리 메모리에 적재하는 방법은 비효율적이다.
- 그러므로, 해당 프로그램에서 실제 필요로 하는 부분만을 물리 메모리에 적재하는 기법을 `요구 페이징`이라고 한다.
- 가상 메모리에서는 `페이지`들이 실행 과정에서 실제로 필요할 때 물리 메모리에 적재되므로 실행 과정 중에서 한번도 접근되지 않은 `페이지`는 물리 메모리에 적재되지 않는다.
- 프로세스는 보통 `예비 저장장치 (혹은 스왑 장치)`에 상주하고 있는데, 프로세스를 실행 할 때  물리 메모리에 적재된다.



#### 3-1. 기본 개념

- `스와핑` 개념에서 어떤 페이지가 물리 메모리에 적재되어 있는지 아닌지를 확인하기 위한 수단이 필요하다.
- 이를 위해서, `유효 비트(valid bit)` 를 사용하는데, `유효 비트`가 1로 설정되어 있으면 현재 페이지가 물리 메모리에 적재되었다는 뜻이고, `유효 비트`가 0으로 설정되어 있으면 물리 메모리에 존재하지 않고 `예비 저장장치`에 존재한다는 것을 뜻한다.



#### 페이지 크기가 작은 경우 VS 큰 경우

 1. 페이지 크기가 작은 경우	

    - 페이지 크기가 `작은 경우`에는 내부 단편화의 크기 또한 작아진다.

    - 페이지의 크기를 N이라고 했을 때, 해당 프로그램이 N의 배수로 나누어 떨어지지 않는다면 내부 단편화 크기의 범위는 `0 ~ (N-1)`까지의 크기를 갖게 된다.
    - 또한, `PMT`의 크기는 커지고 `페이지 부재율` 또한 증가한다는 단점이 있다.
    - `스왑 장치`에서 크기가 작은 페이지를 가져오는데 걸리는 `입출력`시간은 작지만 `페이지 부재`가 발생하는 횟수에 따른 `페이지 교체`의 횟수가 증가됨에 따라 전체 `입출력`시간이 증가할 수 있다.

	2. 페이지 크기가 큰 경우

    - 페이지 크기가 `큰 경우`에는 내부 단편화의 크기가 커지지만 `PMT`의 크기는 작아진다.
    -  `PMT`의 크기는 작아지고 `페이지 부재율` 또한 감소한다는 장점이 있다.
    - 페이지의 크기가 크면 `당장 필요없는 부분`도 메모리에 적재시키기 때문에 메모리 효율성이 떨어진다는 단점이 있다.
    - 또한, `스왑 장치`에서 크기가 큰 페이지를 가져오는 데 걸리는 `입출력`시간이 오래걸린다. 



#### 3-2. 페이지 부재 (Page fault)

- 프로세스가 메모리에 올라와 있지 않는 페이지를 접근하려고 하는 것을 `페이지 부재`라고 한다.

<img src="C:/workspace/GitRepository/TIL/운영체제/자료/페이지부재처리과정.png" style="zoom:60%;" />

1. CPU가 `load M`이라는 명령어를 수행한다고 가정하자. CPU가 발생시킨 논리주소에 의해서 해당 페이지가 존재하는 지 확인한다.
2. 페이징 하드웨어는  `유효 비트`를 확인하여 무효한 참조라면 해당 프로세스를 종료시키고, 유효한 참조인데 물리 메모리에 적재되지 않은 상태라면 운영체제에게 트랩을 건다.
3. 운영체제는 `예비 저장장치`에서 해당 페이지가 존재하는지 확인을 한다.
4. 물리 메모리에서 `자유 프레임(Free Frame)`을 찾아 해당 페이지를 적재시킨다.
5. 페이지 테이블의 `유효 비트`를 갱신한다.
6. 트랩에 의해 중단되었던 명령어를 다시 수행한다.



- 물리 메모리에 페이지가 하나도 올라오지 않은 극단적인 상황에서도 프로세스를 실행할 수 있다. 
- 이 과정에서는 프로세스가 필요로 하는 모든 페이지가 적재될 때 까지 `페이지 부재`가 발생하게 된다.
- 필요한 페이지가 모두 적재되고 나면, 그 다음부터는 `페이지 부재`가 발생하지 않는데, 이것을 `순수 요구 페이징 (Pure Demand Pagin)` 이라고 한다.

#### * 페이지 부재와 프레임의 관계

- `페이지 부재` 횟수를 알고자 한다면, `페이지 교체 알고리즘`외에도 `프레임의 수`를 알 필요가 있다.
- `프레임의 수`가 커질수록 `페이지 부재` 횟수도 줄어드는 것이 일반적이다.
- 그러나, `Belady 모순`을 통해 알 수 있듯이 프레임의 수를 증가시키더라도 페이지 부재 횟수가 더 높아지는 경우도 존재한다.



#### 3-3. 요구 페이징의 성능

1. P : 페이지 부재가 발생할 확률
2. T<sub>m</sub> : 메모리 접근시간
3. T<sub>p</sub> : 페이지 부재 처리시간
4. T<sub>eff</sub> = (1-P) * T<sub>m</sub> + P * T<sub>p</sub> 으로 나타낼 수 있다.

- `페이지 부재`를 처리하는 데 걸리는 시간은 아래와 같다.
  - 디스크의 헤더가 데이터가 저장된 위치로 옮기는 시간 (seek time)
  - 디스크가 한바퀴 도는 시간 (rotational time)
  - 디스크로부터 데이터를 읽는 시간 (transfer time)

------

### 4. 페이지 교체 (Page Replacement)

- 만약 빈 프레임이 없다면, 현재 사용되고 있지 않는 프레임을 찾아서 그것을 비워버린다.
- 그 프레임의 내용을 `스왑 장치` 에 쓰고 그 페이지가 메모리에 더 이상 존재하지 않는다는 것을 알리기 위해 `페이지 테이블`을 갱신한다.



#### 4-1. 페이지 교체 과정

![](C:/workspace/GitRepository/TIL/운영체제/자료/페이지교체.png)

1. 디스크에서 필요한 페이지의 위치를 알아낸다.
2. 빈 페이지 프레임을 찾는다
   - 빈 프레임이 있다면 사용한다.
   - 빈 프레임이 없다면
     - 희생될 프레임을 선정하기 위하여 `페이지 교체 알고리즘`을 가동한다.
     - 희생 페이지를 디스크에 기록하고 (변경된 사항을 다시 write) 관련된 페이지 테이블을 수정한다.
3. 새로운 페이지를 프레임에 할당하고, 페이지 테이블을 갱신한다.
4. `페이지 부재`가 발생한 지점에서부터 프로세스를 계속 실행한다.



- 위의 과정에서 디스크에 접근하는 횟수가 두번임을 알 수 있다.

------

### 5. 참조열 (Reference String)

- 페이지 p에 대한 참조가 발생하면, 직후에 p에 접근하는 모든 참조는 `페이지 부재`를 발생시키지 않는다.
- 따라서, CPU가 생성하는 논리주소(페이지 단위)에 따라 `페이지 부재`가 발생하지 않는 부분은 생략하여 표시하는 방법을 `Reference String`이라고 한다.

#### 문제) 페이지 크기가 100바이트 일 때, 다음 메모리 주소를 `참조 열`로 변환하라.

- 0100, 0432, 0101, 0612, 0102, 0103, 0104, 0101, 0611, 0102, 0103, 0104, 0101, 0610, 0102, 0103, 0104, 0101, 0609, 0102, 0105
- 답) 1 4 1 6 1 6 1 6 1 6 1

------

### 6. 정적 페이지 교체 알고리즘 (Fixed Allocation)

- 다음과 같은 `참조열 (Reference String)`이 있다고 가정한다.
- `7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0 ,3, 2, 1, 2, 0, 1, 7, 0, 1`



#### 6-1. FIFO 페이지 교체

- `FIFO 알고리즘`은 어떤 페이지를 교체할 때, 메모리에 올라온 지가 가장 오래된 페이지를 내쫓는 방법이다.
- 페이지가 올라온 시간을 기억해도 되고, 페이지들이 올라온 순서로 큐를 만들어가지고 있어도 된다.
- 아래는 `프레임`이 3개일 때, `FIFO 알고리즘`을 적용한 예시이다.

![](https://t1.daumcdn.net/cfile/tistory/256403335916A03E18)

- `FIFO 알고리즘`은 이해하기도 쉽고, 프로그래밍하기도 쉽지만 성능이 좋은 편은 아니다.
- `FIFO 알고리즘`에서는 프레임의 수를 증가시켰음에도 불구하고 `페이지 부재` 횟수가 증가하는 `Belady 모순`이 발생하기도 한다.



#### 6-2. 최적 페이지 교체 (Optimal Page Replacement)

- `OPT 알고리즘`은 앞으로 가장 오랫 동안 사용되지 않을 페이지를 찾아 교체하는 알고리즘이다.
- 이 방법은 모든 알고리즘보다 낮은 `페이지 부재율`을 보이며 `Belady 모순`이 발생하지 않는다.

![](https://t1.daumcdn.net/cfile/tistory/265B26335916A03F39)

- 그러나, 이 알고리즘은 미래에 실행될 프로세스가 어떻게 메모리를 참조할 것인지 미리 알아야 하기 때문에 구현이 불가능하다는 단점이 있다.
- 단, `OPT 알고리즘`은 다른 어떤 페이지 알고리즘보다도 성능이 좋으므로, 다른 알고리즘의 성능을 평가할 때 사용된다.



#### 6-3. LRU 페이지 교체 (Least-Recently-Used Page Replacement)

- `OPT 알고리즘`과 같이 미래를 예상할 수 없다면, 과거의 기록(?)을 통해 미래에 대한 근사치를 추정함으로써 최적에 근사한 알고리즘을 구현할 수 있다.
- `LRU 알고리즘`은 최근에 사용되지 않은, 즉 가장 오랜 시간동안 참조되지 않은 페이지를 찾아 교체하는 알고리즘이다.
- 과거에도 사용되지 않았다면, 앞으로도 사용되지 않을 확률이 높다고 생각하는 것이다.
- `LRU 알고리즘`은 각 페이지마다 마지막으로 참조된 시간을 유지한다.

![](https://t1.daumcdn.net/cfile/tistory/2724AE335916A04007)

- Loop 실행에 필요한 크기보다 작은 수의 페이지 프레임이 할당된 경우 `페이지 부재율`이 급격히 증가한다. 예를 들어, 프레임의 크기는 3이고, Loop 실행에서 참조하는 페이지의 크기가 4인 경우가 그렇다.
- `LRU 알고리즘`을 구현하기 위해서는 프레임들을 최근 사용된 시간 순서로 파악할 수 있어야 하는데 이를 위해서는 하드웨어의 지원이 필요하다.



1. 계수기 (Counters)
   - 각 페이지 항목마다 사용 시간 필드를 추가하여, 페이지에 대한 참조가 발생할 때 마다 페이지의 사용시간 필드에 시간 레지스터의 값을 복사한다.
   - 시간 값이 가장 작은 페이지가 교체된다.
   - 이 기법은 LRU 페이지를 찾기 위해서 `페이지 테이블`을 탐색하여야 하며 매 메모리 참조시마다 메모리 쓰기 작업을 필요로 한다.
2. 스택 (Stack)
   - 페이지 번호의 스택을 유지하는 방법이다. 페이지가 참조될 때 마다 페이지 번호는 스택 중간에서 제거되어 스택의 Top에 놓이게 된다.
   - 이런 방식으로하면 스택의 Top은 항상 최근에 참조된 페이지이고, 스택의 Bottom은 가장 오랫동안 이용되지 않은 페이지이다.
   - 스택은 보통 `Doubly Linked List`로 구현된다. 



#### 6-4. LFU 페이지 교체 (Least Frequently Used)

- `LFU 알고리즘`은 참조 회수가 가장 적은 페이지를 교체하는 방법이다.
- 이 알고리즘은 참조된 횟수가 많은 페이지일수록 앞으로도 참조될 가능성이 높다고 가정하는 것이다.
- 그러나, 어떤 프로세스가 임의의 페이지 P에 대해서 초기 단계에 집중적으로 참조한 이후에 다시는 그 페이지를 사용하지 않게 된다면, P페이지는 계속해서 메모리에 상주하게 된다.
- 이 문제를 해결하기 위한 방법은, 참조 횟수를 일정한 시간마다 오른쪽으로 시프트해서 그 수를 감소시키는 방법이 있다.

#### 6-5. MFU 페이지 교체 (Most Frequently Used)

- `MFU 알고리즘`은 가장 적은 참조 횟수를 가진 페이지가 가장 최근에 참조되었고 앞으로도 사용될 것이라는 판단에 근거한 방법이다.
- 이러한 오버헤드를 피하기 위해 `변경 비트(modify bit or dirty bit)`라고 하는 비트를 사용해서 감소시킬 수 있다. CPU내의 페이지가 수정이 발생하면 `변경 비트`를 설정한다.
- `희생 페이지`를 선택한 뒤, `예비 저장장치`로 내보내기 전에 `변경 비트`를 확인하여 수정이 발생했으면 디스크에 다시 저장한다.

#### 6-6. NUR 페이지 교체 (Not Used Recently)

- 최근에 사용되지 않은 페이지를 교체하는 알고리즘으로 `LRU`와 비슷하지만, `LRU`에서 발생하는 오버헤드를 보완하기 위한 교체 알고리즘이다.
- `NUR` 알고리즘은 최근에 사용 여부를 확인하기 위해서 각 페이지마다 두개의 비트 (참조 비트, 변형 비트) 를 사용한다.
- 참조비트가 0이면 오래전에 호출한 것이고 1이면 최근에 호출한 것이다.
- 변형비트가 0이면 오래전에 사용한 것이고 1이면 최근에 사용한 것이다.

| 페이지 번호 | 참조(호출) 비트 | 변형(사용) 비트 |
| ----------- | --------------- | --------------- |
| 1           | 1               | 0               |
| 2           | 0               | 1               |
| 3           | 1               | 1               |
| 4           | 0               | 0               |

- 페이지 교체 순서는 `4 -> 2 -> 1 -> 3` 이다.

#### 6-7. 이차 기회 교체 (Second-Chance)

- 가장 오래된 페이지가 최근에 사용될 가능성이 높을 것이라는 가정하는 것이다.
- 가장 오래된 페이지는 교체 대상에서 제외하고 나머지 페이지들 중에서 `희생`페이지를 찾는 것이다.
- 즉, `LRU 교체 알고리즘과 FIFO 교체 알고리즘`을 함께 사용하는 방식이다.

---

### 7. 정적 프레임 할당 (Static Frame Allocation)

1. 균등 할당 (Equal allocation)
   - `균등 할당` 방식은 모든 프로세스들에게 똑같은 수의 프레임을 할당하는 것이다.
2. 비례 할당 (Proportional allocation)
   - 각 프로세스들의 크기가 다르다는 점을 고려하여, 각 프로세스의 크기 비율에 맞추어 할당하는 방법이다.

#### 7-1. 전역 대 지역 할당 (Global Versus Local Allocation)

- 다수의 프로세스가 프레임 할당을 위해 경쟁하는 환경에서 페이지 교체 알고리즘은 크게 두 가지 범주, `전역 교체 (global replacement)`와 `지역 교체(local replacement)`로 나눌 수 있다.

1. 전역 교체
   - `전역 교체` 방식은 프로세스가 교체할 프레임을 다른 프로세스에 속한 프레임을 포함한 모든 프레임에서 교체할 프레임을 찾는 방식이다.
   - `전역 교체` 방식에서는 해당 프로세스보다 우선순위가 낮은 프로세스들의 프레임을 뺏어올 수 있기 때문에, 해당 프로세스에 할당된 프레임의 수는 계속해서 변할 수 있다.
   - 즉, `전역 교체` 방식은 어떤 프로세스들과 함께 실행되느냐에 따라서 페이지 수가 변하기 때문에 그 자신의 `페이지 부재율`을 조절할 수 없다.
2. 지역 교체
   - `지역 교체` 방식은 각 프로세스가 자기에게 할당된 프레임들 중에서만 교체될 페이지를 찾는 방식이다.
   - `지역 교체` 방식에서는 프로세스에 할당된 프레임 수가 변하지 않지만, 잘 안쓰는 페이지 프레임이 있더라도 그것을 그대로 낭비할 수 있다.

---

### 8. 쓰레싱 (Thrashing)

- 운영체제는 CPU의 이용률을 검사하여 CPU 이용률이 너무 낮아지면 새로운 프로세스를 시스템에 더 추가해서 다중 프로그래밍의 정도를 높인다.
- 처음에는 다중 프로그래밍의 정도가 높아짐에 따라 `CPU 이용률`도 함께 증가하지만, 프로세스가 많아질 수록 `페이지 부재율`은 높아질 것이다.
- 이로 인해, 실제로 프로세스가 실행되는 시간보다 페이지 교체를 기다리기 위한 시간 (Swaping에 필요한) 이 더 커지게 되는데, 이러한 상황에서 `준비 완료 큐`는 비어있게 되어 CPU 이용률은 더 낮아지게 된다.
- CPU 이용률이 낮아질 수록, 운영체제는 다중 프로그래밍 정도를 더욱 높이려고 할 것이고 결국에는 어떤 프로세스도 실행될 수 없는 상황에 직면하게 된다.

![](https://t1.daumcdn.net/cfile/tistory/24388A4057188EAD38)

---

### 9. 동적 프레임 할당 (Variable Frame Allocation)

- 각 프로세스에 할당되는 프레임의 수를 가변적으로 제공하는 방식이다.

#### 9-1. 작업 집합 모델 (Working-Set Model)

- `작업 집합 모델`은 지역성을 토대로 하고 있다.
- 프로세스가 특정 시점에 자주 참조하는 페이지들의 집합, 최근 일정시간(△) 참조된 페이지들의 집합을 살펴본다.

![](http://blog.skby.net/blog/wp-content/uploads/2019/04/1-37.png)

- 즉, `작업 집합` 의 크기가 해당 프로세스에 할당되는 프레임의 크기이다.
- Window size(△) 값이 성능을 결정 짓는 중요한 요소이다.



#### 10-2. 페이지 부재 빈도 (PFF, Page-Fault Frequency)

- `페이지 부재율`이 너무 높으면, 그 프로세스가 더 많은 프레임을 요구한다는 뜻이고, `페이지 부재율`이 너무 낮으면, 그 프로세스에 너무 많은 프레임이 할당되어 있다는 뜻이다.
- 따라서, `페이지 부재율`의 상한선과 하한선을 정해놓고 만약 `페이지 부재율`이 상한선을 넘으면 그 프로세스에 프레임을 더 할당하고, 하한선을 넘으면 그 프로세스의 프레임 수를 줄인다.

![](http://blog.skby.net/blog/wp-content/uploads/2019/04/1-38.png)

---

### 11. 페이지의 크기

- `페이지 크기`를 감소시키는 것은 페이지의 수를 증가시키고, 결국 `페이지 테이블`의 크기를 증가시킨다.
- 반면에, 메노리 사용 효율을 위해서는 `페이지 크기`가 작은 것이 좋다.  페이지의 크기가 크다보면, 프로세스가 사용하지 않는 영역도 메모리에 적재될 가능성이 높아진다.
- 즉, 큰 페이지 시스템에서는 꼭 필요한 내용뿐 아니라 우연히 같은 페이지에 속한 모든 정보들도 함께 적재되므로 메모리 사용 효율이 낮아진다.
- 그러나, `페이지 부재 횟수`를 줄이기 위해서는 `페이지 크기`가 큰 것이 좋다. `페이지 크키`가 매우 작다면 매 접근마다 모두 `페이지 부재`가 발생할 것이다.